{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3e2e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import sys\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch.nn.init as init\n",
    "from typing import Any\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57f39d",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c455a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(25)\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d2b84d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43693a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet.classifier[1] = nn.Linear(9216,4096)\n",
    "alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "alexnet.classifier[6] = nn.Linear(1024,2)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f25951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute mean and std for training data.\n",
      "5000\n",
      "([0.32524452, 0.32524452, 0.32524452], [0.3328115, 0.3328115, 0.3328115])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def getStat(train_data):\n",
    "    print('Compute mean and std for training data.')\n",
    "    print(len(train_data))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=1, shuffle=False, num_workers=0,\n",
    "        pin_memory=True)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        for d in range(3):\n",
    "            mean[d] += X[:, d, :, :].mean()\n",
    "            std[d] += X[:, d, :, :].std()\n",
    "    mean.div_(len(train_data))\n",
    "    std.div_(len(train_data))\n",
    "    return list(mean.numpy()), list(std.numpy())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = ImageFolder(root=os.getcwd()+ \"/downloads/COVID-19-3/Train/\", transform=transforms.ToTensor())  #get_transform_for_train()\n",
    "    print(getStat(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e473a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.32524452, 0.32524452, 0.32524452], std=[0.3328115, 0.3328115, 0.3328115]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769cdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os, os.path\n",
    "\n",
    "data_root = os.getcwd()\n",
    "image_path = data_root + \"/downloads/COVID-19-3/Train/\"\n",
    "train_dataset = datasets.ImageFolder(root = image_path, transform = preprocess)\n",
    "lung_list = train_dataset.class_to_idx\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "batch_size = 4\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root = data_root + \"/downloads/COVID-19-3/Test/\", transform = preprocess)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "classes = (\"Normal\", \"Abnormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7bb467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   625] loss: 0.551\n",
      "Time: 110.96156191825867\n",
      "[1,  1250] loss: 0.416\n",
      "Time: 220.21117496490479\n",
      "Epoch 1 : Train accuracy: 86.02 % , Test accuracy: 80.60 %\n",
      "[2,   625] loss: 0.331\n",
      "Time: 111.2601363658905\n",
      "[2,  1250] loss: 0.289\n",
      "Time: 220.4559624195099\n",
      "Epoch 2 : Train accuracy: 90.78 % , Test accuracy: 85.20 %\n",
      "[3,   625] loss: 0.240\n",
      "Time: 111.65208292007446\n",
      "[3,  1250] loss: 0.198\n",
      "Time: 221.31571865081787\n",
      "Epoch 3 : Train accuracy: 94.24 % , Test accuracy: 88.60 %\n",
      "[4,   625] loss: 0.172\n",
      "Time: 111.2907567024231\n",
      "[4,  1250] loss: 0.157\n",
      "Time: 220.48897576332092\n",
      "Epoch 4 : Train accuracy: 93.60 % , Test accuracy: 93.40 %\n",
      "[5,   625] loss: 0.143\n",
      "Time: 111.39577579498291\n",
      "[5,  1250] loss: 0.129\n",
      "Time: 220.57765316963196\n",
      "Epoch 5 : Train accuracy: 95.06 % , Test accuracy: 89.60 %\n",
      "[6,   625] loss: 0.102\n",
      "Time: 111.22350358963013\n",
      "[6,  1250] loss: 0.090\n",
      "Time: 220.50161862373352\n",
      "Epoch 6 : Train accuracy: 95.60 % , Test accuracy: 86.40 %\n",
      "[7,   625] loss: 0.068\n",
      "Time: 111.24895191192627\n",
      "[7,  1250] loss: 0.066\n",
      "Time: 221.73560667037964\n",
      "Epoch 7 : Train accuracy: 96.68 % , Test accuracy: 87.00 %\n",
      "[8,   625] loss: 0.065\n",
      "Time: 111.1503598690033\n",
      "[8,  1250] loss: 0.062\n",
      "Time: 220.6362223625183\n",
      "Epoch 8 : Train accuracy: 99.34 % , Test accuracy: 96.40 %\n",
      "[9,   625] loss: 0.037\n",
      "Time: 112.20994997024536\n",
      "[9,  1250] loss: 0.042\n",
      "Time: 222.41075038909912\n",
      "Epoch 9 : Train accuracy: 97.94 % , Test accuracy: 96.00 %\n",
      "[10,   625] loss: 0.019\n",
      "Time: 112.00828099250793\n",
      "[10,  1250] loss: 0.041\n",
      "Time: 222.07711458206177\n",
      "Epoch 10 : Train accuracy: 99.48 % , Test accuracy: 97.60 %\n",
      "[11,   625] loss: 0.026\n",
      "Time: 111.05632948875427\n",
      "[11,  1250] loss: 0.049\n",
      "Time: 220.13069462776184\n",
      "Epoch 11 : Train accuracy: 99.70 % , Test accuracy: 95.00 %\n",
      "[12,   625] loss: 0.020\n",
      "Time: 111.16106081008911\n",
      "[12,  1250] loss: 0.033\n",
      "Time: 220.33236289024353\n",
      "Epoch 12 : Train accuracy: 99.66 % , Test accuracy: 98.20 %\n",
      "[13,   625] loss: 0.020\n",
      "Time: 110.93647861480713\n",
      "[13,  1250] loss: 0.009\n",
      "Time: 219.79838919639587\n",
      "Epoch 13 : Train accuracy: 99.80 % , Test accuracy: 97.20 %\n",
      "[14,   625] loss: 0.004\n",
      "Time: 111.14550256729126\n",
      "[14,  1250] loss: 0.034\n",
      "Time: 220.37780714035034\n",
      "Epoch 14 : Train accuracy: 99.84 % , Test accuracy: 95.60 %\n",
      "[15,   625] loss: 0.016\n",
      "Time: 111.23171043395996\n",
      "[15,  1250] loss: 0.032\n",
      "Time: 220.42271614074707\n",
      "Epoch 15 : Train accuracy: 99.18 % , Test accuracy: 95.40 %\n",
      "[16,   625] loss: 0.006\n",
      "Time: 110.99993371963501\n",
      "[16,  1250] loss: 0.003\n",
      "Time: 220.05158138275146\n",
      "Epoch 16 : Train accuracy: 99.98 % , Test accuracy: 98.00 %\n",
      "[17,   625] loss: 0.006\n",
      "Time: 110.93570160865784\n",
      "[17,  1250] loss: 0.008\n",
      "Time: 219.84227633476257\n",
      "Epoch 17 : Train accuracy: 99.98 % , Test accuracy: 97.00 %\n",
      "[18,   625] loss: 0.026\n",
      "Time: 110.88405179977417\n",
      "[18,  1250] loss: 0.003\n",
      "Time: 219.78690576553345\n",
      "Epoch 18 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[19,   625] loss: 0.001\n",
      "Time: 110.99726486206055\n",
      "[19,  1250] loss: 0.006\n",
      "Time: 219.98111772537231\n",
      "Epoch 19 : Train accuracy: 99.08 % , Test accuracy: 95.60 %\n",
      "[20,   625] loss: 0.009\n",
      "Time: 110.90959787368774\n",
      "[20,  1250] loss: 0.001\n",
      "Time: 219.88244128227234\n",
      "Epoch 20 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[21,   625] loss: 0.016\n",
      "Time: 110.87399744987488\n",
      "[21,  1250] loss: 0.001\n",
      "Time: 219.86200857162476\n",
      "Epoch 21 : Train accuracy: 99.88 % , Test accuracy: 97.80 %\n",
      "[22,   625] loss: 0.000\n",
      "Time: 110.92156076431274\n",
      "[22,  1250] loss: 0.000\n",
      "Time: 219.9222114086151\n",
      "Epoch 22 : Train accuracy: 100.00 % , Test accuracy: 98.00 %\n",
      "[23,   625] loss: 0.000\n",
      "Time: 111.54632306098938\n",
      "[23,  1250] loss: 0.006\n",
      "Time: 221.35568165779114\n",
      "Epoch 23 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[24,   625] loss: 0.000\n",
      "Time: 110.19388937950134\n",
      "[24,  1250] loss: 0.000\n",
      "Time: 218.54307293891907\n",
      "Epoch 24 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[25,   625] loss: 0.000\n",
      "Time: 110.38484621047974\n",
      "[25,  1250] loss: 0.000\n",
      "Time: 218.83064222335815\n",
      "Epoch 25 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[26,   625] loss: 0.000\n",
      "Time: 110.47827124595642\n",
      "[26,  1250] loss: 0.000\n",
      "Time: 218.7977876663208\n",
      "Epoch 26 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[27,   625] loss: 0.000\n",
      "Time: 110.46226024627686\n",
      "[27,  1250] loss: 0.000\n",
      "Time: 218.8366813659668\n",
      "Epoch 27 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[28,   625] loss: 0.000\n",
      "Time: 110.74205946922302\n",
      "[28,  1250] loss: 0.000\n",
      "Time: 219.1399347782135\n",
      "Epoch 28 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[29,   625] loss: 0.000\n",
      "Time: 111.04014420509338\n",
      "[29,  1250] loss: 0.000\n",
      "Time: 220.23719882965088\n",
      "Epoch 29 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[30,   625] loss: 0.000\n",
      "Time: 110.44933438301086\n",
      "[30,  1250] loss: 0.000\n",
      "Time: 219.7293426990509\n",
      "Epoch 30 : Train accuracy: 100.00 % , Test accuracy: 98.80 %\n",
      "[31,   625] loss: 0.000\n",
      "Time: 112.43183207511902\n",
      "[31,  1250] loss: 0.000\n",
      "Time: 222.84583640098572\n",
      "Epoch 31 : Train accuracy: 100.00 % , Test accuracy: 98.80 %\n",
      "[32,   625] loss: 0.000\n",
      "Time: 112.2035665512085\n",
      "[32,  1250] loss: 0.000\n",
      "Time: 222.55261778831482\n",
      "Epoch 32 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[33,   625] loss: 0.000\n",
      "Time: 112.30523371696472\n",
      "[33,  1250] loss: 0.000\n",
      "Time: 223.70244550704956\n",
      "Epoch 33 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[34,   625] loss: 0.000\n",
      "Time: 112.5697455406189\n",
      "[34,  1250] loss: 0.000\n",
      "Time: 222.95711088180542\n",
      "Epoch 34 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[35,   625] loss: 0.000\n",
      "Time: 112.13948678970337\n",
      "[35,  1250] loss: 0.000\n",
      "Time: 222.63009762763977\n",
      "Epoch 35 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[36,   625] loss: 0.000\n",
      "Time: 112.58886790275574\n",
      "[36,  1250] loss: 0.000\n",
      "Time: 223.28479146957397\n",
      "Epoch 36 : Train accuracy: 100.00 % , Test accuracy: 98.80 %\n",
      "[37,   625] loss: 0.000\n",
      "Time: 112.35520386695862\n",
      "[37,  1250] loss: 0.000\n",
      "Time: 222.74956154823303\n",
      "Epoch 37 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[38,   625] loss: 0.000\n",
      "Time: 112.46435308456421\n",
      "[38,  1250] loss: 0.000\n",
      "Time: 223.17746424674988\n",
      "Epoch 38 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[39,   625] loss: 0.000\n",
      "Time: 112.39243483543396\n",
      "[39,  1250] loss: 0.000\n",
      "Time: 222.72110676765442\n",
      "Epoch 39 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[40,   625] loss: 0.000\n",
      "Time: 112.27672982215881\n",
      "[40,  1250] loss: 0.000\n",
      "Time: 223.0102458000183\n",
      "Epoch 40 : Train accuracy: 100.00 % , Test accuracy: 98.20 %\n",
      "[41,   625] loss: 0.000\n",
      "Time: 112.7474536895752\n",
      "[41,  1250] loss: 0.000\n",
      "Time: 223.11439061164856\n",
      "Epoch 41 : Train accuracy: 100.00 % , Test accuracy: 98.80 %\n",
      "[42,   625] loss: 0.000\n",
      "Time: 112.87297010421753\n",
      "[42,  1250] loss: 0.000\n",
      "Time: 223.2310996055603\n",
      "Epoch 42 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[43,   625] loss: 0.000\n",
      "Time: 112.38789772987366\n",
      "[43,  1250] loss: 0.000\n",
      "Time: 223.22362351417542\n",
      "Epoch 43 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[44,   625] loss: 0.000\n",
      "Time: 112.64726543426514\n",
      "[44,  1250] loss: 0.000\n",
      "Time: 223.15643429756165\n",
      "Epoch 44 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[45,   625] loss: 0.000\n",
      "Time: 112.33673048019409\n",
      "[45,  1250] loss: 0.000\n",
      "Time: 223.25265336036682\n",
      "Epoch 45 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[46,   625] loss: 0.000\n",
      "Time: 112.55471110343933\n",
      "[46,  1250] loss: 0.000\n",
      "Time: 223.39793848991394\n",
      "Epoch 46 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[47,   625] loss: 0.000\n",
      "Time: 112.82110023498535\n",
      "[47,  1250] loss: 0.000\n",
      "Time: 223.40068531036377\n",
      "Epoch 47 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[48,   625] loss: 0.000\n",
      "Time: 112.47996520996094\n",
      "[48,  1250] loss: 0.000\n",
      "Time: 223.3911681175232\n",
      "Epoch 48 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "[49,   625] loss: 0.000\n",
      "Time: 112.48092794418335\n",
      "[49,  1250] loss: 0.000\n",
      "Time: 222.99087858200073\n",
      "Epoch 49 : Train accuracy: 100.00 % , Test accuracy: 98.40 %\n",
      "[50,   625] loss: 0.000\n",
      "Time: 112.62175869941711\n",
      "[50,  1250] loss: 0.000\n",
      "Time: 222.79917192459106\n",
      "Epoch 50 : Train accuracy: 100.00 % , Test accuracy: 98.60 %\n",
      "Finished Training of AlexNet\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(alexnet.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "acc_t = []\n",
    "acc_v = []\n",
    "epoch_counts = []\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_iter, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = alexnet(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 625 == 624:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 625))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in train_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_t += labels.size(0)\n",
    "            correct_t += (predicted == labels).sum().item()\n",
    "    acc_t.append(correct_t / total_t)\n",
    "            \n",
    "    correct_v = 0\n",
    "    total_v = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_v += labels.size(0)\n",
    "            correct_v += (predicted == labels).sum().item()\n",
    "    acc_v.append(correct_v / total_v)\n",
    "    \n",
    "    epoch_counts.append(epoch + 1)\n",
    "            \n",
    "    print('Epoch', epoch + 1,': Train accuracy: %.2f %%' % (100 * correct_t / total_t), ', Test accuracy: %.2f %%' % (100 * correct_v / total_v))\n",
    "    \n",
    "print('Finished Training of AlexNet')\n",
    "\n",
    "plt.plot(epoch_counts, acc_t)\n",
    "plt.plot(epoch_counts, acc_v)\n",
    "plt.title('AlexNet accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d584b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of FP for Normal : 6\n",
      "Numbers of FN for Normal : 3\n",
      "Precision of Normal : 97 %\n",
      "Recall of Normal : 98 %\n",
      "Accuracy of Normal : 98 %\n",
      "F1-score of Normal : 98 %\n",
      "\n",
      "Numbers of FP for Abnormal : 3\n",
      "Numbers of FN for Abnormal : 6\n",
      "Precision of Abnormal : 98 %\n",
      "Recall of Abnormal : 97 %\n",
      "Accuracy of Abnormal : 97 %\n",
      "F1-score of Abnormal : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "class_FP_TP = list(0. for i in range(10))\n",
    "class_TN_FN = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_iter:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c0 = (predicted == 0).squeeze()\n",
    "        c1 = (predicted == 1).squeeze()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_FP_TP[label] += c1[i].item()\n",
    "            class_TN_FN[label] += c0[i].item()\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "Precision0 = 100 * class_TN_FN[0] / (class_TN_FN[0] + class_TN_FN[1])\n",
    "Recall0 = 100 * class_TN_FN[0]/ (class_TN_FN[0] + class_FP_TP[0])\n",
    "F10 = 2 * (Precision0 * Recall0) / (Precision0 + Recall0)\n",
    "print('Numbers of FP for', classes[0], ':', int(class_TN_FN[1]))\n",
    "print('Numbers of FN for', classes[0], ':', int(class_FP_TP[0]))\n",
    "print('Precision of %5s : %2d %%' % (classes[0], Precision0))\n",
    "print('Recall of %5s : %2d %%' % (classes[0], Recall0))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[0], 100 * class_correct[0] / class_total[0]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[0], F10))\n",
    "print()\n",
    "\n",
    "Precision1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_FP_TP[0])\n",
    "Recall1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_TN_FN[1])\n",
    "F11 = 2 * (Precision1 * Recall1) / (Precision1 + Recall1)\n",
    "print('Numbers of FP for', classes[1], ':', int(class_FP_TP[0]))\n",
    "print('Numbers of FN for', classes[1], ':', int(class_TN_FN[1]))\n",
    "print('Precision of %5s : %2d %%' % (classes[1], Precision1))\n",
    "print('Recall of %5s : %2d %%' % (classes[1], Recall1))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[1], 100 * class_correct[1] / class_total[1]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[1], F11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ae83d",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09403cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(25)\n",
    "\n",
    "class Fire(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        squeeze_planes: int,\n",
    "        expand1x1_planes: int,\n",
    "        expand3x3_planes: int\n",
    "    ) -> None:\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "class SqueezeNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        version: str = '1_0',\n",
    "        num_classes: int = 1000\n",
    "    ) -> None:\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if version == '1_0':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(96, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        elif version == '1_1':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(64, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        else:\n",
    "            # FIXME: Is this needed? SqueezeNet should only be called from the\n",
    "            # FIXME: squeezenet1_x() functions\n",
    "            # FIXME: This checking is not done for the other models\n",
    "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
    "                             \"1_0 or 1_1 expected\".format(version=version))\n",
    "\n",
    "        # Final convolution is initialized differently from the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is final_conv:\n",
    "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n",
    "    \n",
    "def _squeezenet(version: str, pretrained: bool, progress: bool, **kwargs: Any) -> SqueezeNet:\n",
    "    model = SqueezeNet(version, **kwargs)\n",
    "    if pretrained:\n",
    "        arch = 'squeezenet' + version\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a7d6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezenet = SqueezeNet()\n",
    "squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b07a62e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezenet.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88f01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os, os.path\n",
    "\n",
    "data_root = os.getcwd()\n",
    "image_path = data_root + \"/downloads/COVID-19-3/Train/\"\n",
    "train_dataset = datasets.ImageFolder(root = image_path, transform = preprocess)\n",
    "lung_list = train_dataset.class_to_idx\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "batch_size = 16\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root = data_root + \"/downloads/COVID-19-3/Test/\", transform = preprocess)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "classes = (\"Normal\", \"Abnormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3df74a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 0.030\n",
      "Time: 186.5429036617279\n",
      "Epoch 1 : Train accuracy: 81.21 % , Test accuracy: 72.78 %\n",
      "[2,   300] loss: 0.024\n",
      "Time: 186.52884030342102\n",
      "Epoch 2 : Train accuracy: 84.07 % , Test accuracy: 76.61 %\n",
      "[3,   300] loss: 0.021\n",
      "Time: 186.8143346309662\n",
      "Epoch 3 : Train accuracy: 59.98 % , Test accuracy: 49.80 %\n",
      "[4,   300] loss: 0.026\n",
      "Time: 187.29887771606445\n",
      "Epoch 4 : Train accuracy: 88.00 % , Test accuracy: 79.03 %\n",
      "[5,   300] loss: 0.016\n",
      "Time: 187.24760818481445\n",
      "Epoch 5 : Train accuracy: 86.40 % , Test accuracy: 83.06 %\n",
      "[6,   300] loss: 0.016\n",
      "Time: 187.37172722816467\n",
      "Epoch 6 : Train accuracy: 93.23 % , Test accuracy: 87.90 %\n",
      "[7,   300] loss: 0.013\n",
      "Time: 187.62095546722412\n",
      "Epoch 7 : Train accuracy: 91.85 % , Test accuracy: 83.06 %\n",
      "[8,   300] loss: 0.013\n",
      "Time: 187.23666834831238\n",
      "Epoch 8 : Train accuracy: 91.45 % , Test accuracy: 90.32 %\n",
      "[9,   300] loss: 0.011\n",
      "Time: 187.48887467384338\n",
      "Epoch 9 : Train accuracy: 86.32 % , Test accuracy: 85.89 %\n",
      "[10,   300] loss: 0.012\n",
      "Time: 187.55624651908875\n",
      "Epoch 10 : Train accuracy: 93.93 % , Test accuracy: 87.70 %\n",
      "[11,   300] loss: 0.009\n",
      "Time: 187.46043801307678\n",
      "Epoch 11 : Train accuracy: 95.05 % , Test accuracy: 90.12 %\n",
      "[12,   300] loss: 0.008\n",
      "Time: 188.37718725204468\n",
      "Epoch 12 : Train accuracy: 94.63 % , Test accuracy: 92.54 %\n",
      "[13,   300] loss: 0.009\n",
      "Time: 187.44104599952698\n",
      "Epoch 13 : Train accuracy: 92.27 % , Test accuracy: 85.28 %\n",
      "[14,   300] loss: 0.008\n",
      "Time: 189.47924184799194\n",
      "Epoch 14 : Train accuracy: 95.21 % , Test accuracy: 95.36 %\n",
      "[15,   300] loss: 0.009\n",
      "Time: 189.40711212158203\n",
      "Epoch 15 : Train accuracy: 93.63 % , Test accuracy: 86.69 %\n",
      "[16,   300] loss: 0.007\n",
      "Time: 187.24040532112122\n",
      "Epoch 16 : Train accuracy: 96.96 % , Test accuracy: 96.37 %\n",
      "[17,   300] loss: 0.007\n",
      "Time: 187.7662913799286\n",
      "Epoch 17 : Train accuracy: 96.09 % , Test accuracy: 91.33 %\n",
      "[18,   300] loss: 0.006\n",
      "Time: 187.56486821174622\n",
      "Epoch 18 : Train accuracy: 97.16 % , Test accuracy: 93.15 %\n",
      "[19,   300] loss: 0.006\n",
      "Time: 187.583744764328\n",
      "Epoch 19 : Train accuracy: 97.24 % , Test accuracy: 97.78 %\n",
      "[20,   300] loss: 0.007\n",
      "Time: 187.04458236694336\n",
      "Epoch 20 : Train accuracy: 96.92 % , Test accuracy: 96.57 %\n",
      "[21,   300] loss: 0.005\n",
      "Time: 187.31969738006592\n",
      "Epoch 21 : Train accuracy: 96.63 % , Test accuracy: 94.76 %\n",
      "[22,   300] loss: 0.005\n",
      "Time: 187.38490176200867\n",
      "Epoch 22 : Train accuracy: 97.90 % , Test accuracy: 97.18 %\n",
      "[23,   300] loss: 0.004\n",
      "Time: 187.58106350898743\n",
      "Epoch 23 : Train accuracy: 98.60 % , Test accuracy: 98.59 %\n",
      "[24,   300] loss: 0.005\n",
      "Time: 187.80410480499268\n",
      "Epoch 24 : Train accuracy: 98.18 % , Test accuracy: 98.59 %\n",
      "[25,   300] loss: 0.005\n",
      "Time: 188.12566924095154\n",
      "Epoch 25 : Train accuracy: 97.92 % , Test accuracy: 96.77 %\n",
      "[26,   300] loss: 0.004\n",
      "Time: 189.49292612075806\n",
      "Epoch 26 : Train accuracy: 98.10 % , Test accuracy: 97.58 %\n",
      "[27,   300] loss: 0.004\n",
      "Time: 189.90633273124695\n",
      "Epoch 27 : Train accuracy: 98.70 % , Test accuracy: 98.19 %\n",
      "[28,   300] loss: 0.005\n",
      "Time: 187.9194483757019\n",
      "Epoch 28 : Train accuracy: 97.28 % , Test accuracy: 94.35 %\n",
      "[29,   300] loss: 0.003\n",
      "Time: 187.92731380462646\n",
      "Epoch 29 : Train accuracy: 98.82 % , Test accuracy: 98.79 %\n",
      "[30,   300] loss: 0.003\n",
      "Time: 188.33814334869385\n",
      "Epoch 30 : Train accuracy: 98.70 % , Test accuracy: 98.19 %\n",
      "[31,   300] loss: 0.005\n",
      "Time: 187.63754868507385\n",
      "Epoch 31 : Train accuracy: 98.40 % , Test accuracy: 96.57 %\n",
      "[32,   300] loss: 0.004\n",
      "Time: 187.70934104919434\n",
      "Epoch 32 : Train accuracy: 98.26 % , Test accuracy: 97.38 %\n",
      "[33,   300] loss: 0.004\n",
      "Time: 187.81047296524048\n",
      "Epoch 33 : Train accuracy: 99.08 % , Test accuracy: 98.79 %\n",
      "[34,   300] loss: 0.003\n",
      "Time: 187.77222681045532\n",
      "Epoch 34 : Train accuracy: 99.16 % , Test accuracy: 98.59 %\n",
      "[35,   300] loss: 0.003\n",
      "Time: 188.10884308815002\n",
      "Epoch 35 : Train accuracy: 99.04 % , Test accuracy: 98.79 %\n",
      "[36,   300] loss: 0.003\n",
      "Time: 188.15723776817322\n",
      "Epoch 36 : Train accuracy: 98.96 % , Test accuracy: 98.79 %\n",
      "[37,   300] loss: 0.002\n",
      "Time: 187.83501482009888\n",
      "Epoch 37 : Train accuracy: 99.20 % , Test accuracy: 98.39 %\n",
      "[38,   300] loss: 0.003\n",
      "Time: 188.0673213005066\n",
      "Epoch 38 : Train accuracy: 98.80 % , Test accuracy: 96.17 %\n",
      "[39,   300] loss: 0.003\n",
      "Time: 188.08579874038696\n",
      "Epoch 39 : Train accuracy: 98.02 % , Test accuracy: 93.95 %\n",
      "[40,   300] loss: 0.002\n",
      "Time: 187.76161003112793\n",
      "Epoch 40 : Train accuracy: 99.44 % , Test accuracy: 98.79 %\n",
      "[41,   300] loss: 0.003\n",
      "Time: 188.2430715560913\n",
      "Epoch 41 : Train accuracy: 98.98 % , Test accuracy: 97.98 %\n",
      "[42,   300] loss: 0.002\n",
      "Time: 187.86135292053223\n",
      "Epoch 42 : Train accuracy: 99.32 % , Test accuracy: 98.79 %\n",
      "[43,   300] loss: 0.005\n",
      "Time: 187.8598575592041\n",
      "Epoch 43 : Train accuracy: 97.96 % , Test accuracy: 97.98 %\n",
      "[44,   300] loss: 0.004\n",
      "Time: 187.43248343467712\n",
      "Epoch 44 : Train accuracy: 98.66 % , Test accuracy: 98.79 %\n",
      "[45,   300] loss: 0.002\n",
      "Time: 188.05927777290344\n",
      "Epoch 45 : Train accuracy: 99.36 % , Test accuracy: 98.19 %\n",
      "[46,   300] loss: 0.002\n",
      "Time: 188.36785912513733\n",
      "Epoch 46 : Train accuracy: 99.54 % , Test accuracy: 98.59 %\n",
      "[47,   300] loss: 0.002\n",
      "Time: 187.78567910194397\n",
      "Epoch 47 : Train accuracy: 99.66 % , Test accuracy: 98.59 %\n",
      "[48,   300] loss: 0.001\n",
      "Time: 189.26624631881714\n",
      "Epoch 48 : Train accuracy: 99.34 % , Test accuracy: 99.19 %\n",
      "[49,   300] loss: 0.002\n",
      "Time: 189.25495290756226\n",
      "Epoch 49 : Train accuracy: 98.32 % , Test accuracy: 97.98 %\n",
      "[50,   300] loss: 0.002\n",
      "Time: 188.77608346939087\n",
      "Epoch 50 : Train accuracy: 99.24 % , Test accuracy: 98.19 %\n",
      "Finished Training of SqueezeNet\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(squeezenet.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "acc_t = []\n",
    "acc_v = []\n",
    "epoch_counts = []\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_iter, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = squeezenet(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 5000))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in train_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = squeezenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_t += labels.size(0)\n",
    "            correct_t += (predicted == labels).sum().item()\n",
    "    acc_t.append(correct_t / total_t)\n",
    "            \n",
    "    correct_v = 0\n",
    "    total_v = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = squeezenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_v += labels.size(0)\n",
    "            correct_v += (predicted == labels).sum().item()\n",
    "    acc_v.append(correct_v / total_v)\n",
    "    \n",
    "    epoch_counts.append(epoch + 1)\n",
    "            \n",
    "    print('Epoch', epoch + 1,': Train accuracy: %.2f %%' % (100 * correct_t / total_t), ', Test accuracy: %.2f %%' % (100 * correct_v / total_v))\n",
    "    \n",
    "print('Finished Training of SqueezeNet')\n",
    "\n",
    "plt.plot(epoch_counts, acc_t)\n",
    "plt.plot(epoch_counts, acc_v)\n",
    "plt.title('SqueezeNet accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1256b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of FP for Normal : 2\n",
      "Numbers of FN for Normal : 0\n",
      "Precision of Normal : 96 %\n",
      "Recall of Normal : 100 %\n",
      "Accuracy of Normal : 100 %\n",
      "F1-score of Normal : 98 %\n",
      "\n",
      "Numbers of FP for Abnormal : 0\n",
      "Numbers of FN for Abnormal : 2\n",
      "Precision of Abnormal : 100 %\n",
      "Recall of Abnormal : 97 %\n",
      "Accuracy of Abnormal : 97 %\n",
      "F1-score of Abnormal : 98 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "class_FP_TP = list(0. for i in range(10))\n",
    "class_TN_FN = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_iter:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = squeezenet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c0 = (predicted == 0).squeeze()\n",
    "        c1 = (predicted == 1).squeeze()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_FP_TP[label] += c1[i].item()\n",
    "            class_TN_FN[label] += c0[i].item()\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "Precision0 = 100 * class_TN_FN[0] / (class_TN_FN[0] + class_TN_FN[1])\n",
    "Recall0 = 100 * class_TN_FN[0]/ (class_TN_FN[0] + class_FP_TP[0])\n",
    "F10 = 2 * (Precision0 * Recall0) / (Precision0 + Recall0)\n",
    "print('Numbers of FP for', classes[0], ':', int(class_TN_FN[1]))\n",
    "print('Numbers of FN for', classes[0], ':', int(class_FP_TP[0]))\n",
    "print('Precision of %5s : %2d %%' % (classes[0], Precision0))\n",
    "print('Recall of %5s : %2d %%' % (classes[0], Recall0))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[0], 100 * class_correct[0] / class_total[0]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[0], F10))\n",
    "print()\n",
    "\n",
    "Precision1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_FP_TP[0])\n",
    "Recall1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_TN_FN[1])\n",
    "F11 = 2 * (Precision1 * Recall1) / (Precision1 + Recall1)\n",
    "print('Numbers of FP for', classes[1], ':', int(class_FP_TP[0]))\n",
    "print('Numbers of FN for', classes[1], ':', int(class_TN_FN[1]))\n",
    "print('Precision of %5s : %2d %%' % (classes[1], Precision1))\n",
    "print('Recall of %5s : %2d %%' % (classes[1], Recall1))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[1], 100 * class_correct[1] / class_total[1]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[1], F11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470220f7",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e263e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1, self).__init__()\n",
    "\n",
    "        self.c1 = nn.Sequential(OrderedDict([\n",
    "            ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s1', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c1(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class C2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C2, self).__init__()\n",
    "\n",
    "        self.c2 = nn.Sequential(OrderedDict([\n",
    "            ('c2', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c2(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class C3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3, self).__init__()\n",
    "\n",
    "        self.c3 = nn.Sequential(OrderedDict([\n",
    "            ('c3', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n",
    "            ('relu3', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c3(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class F4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F4, self).__init__()\n",
    "\n",
    "        self.f4 = nn.Sequential(OrderedDict([\n",
    "            ('f4', nn.Linear(120, 84)),\n",
    "            ('relu4', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.f4(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class F5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F5, self).__init__()\n",
    "\n",
    "        self.f5 = nn.Sequential(OrderedDict([\n",
    "            ('f5', nn.Linear(84, 2)),\n",
    "            ('sig5', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.f5(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    Output - 10\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.c1 = C1()\n",
    "        self.c2_1 = C2() \n",
    "        self.c2_2 = C2() \n",
    "        self.c3 = C3() \n",
    "        self.f4 = F4() \n",
    "        self.f5 = F5() \n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c1(img)\n",
    "\n",
    "        x = self.c2_1(output)\n",
    "        output = self.c2_2(output)\n",
    "\n",
    "        output += x\n",
    "\n",
    "        output = self.c3(output)\n",
    "        output = output.view(img.size(0), -1)\n",
    "        output = self.f4(output)\n",
    "        output = self.f5(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b090a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (c1): C1(\n",
       "    (c1): Sequential(\n",
       "      (c1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (relu1): ReLU()\n",
       "      (s1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (c2_1): C2(\n",
       "    (c2): Sequential(\n",
       "      (c2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (c2_2): C2(\n",
       "    (c2): Sequential(\n",
       "      (c2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (relu2): ReLU()\n",
       "      (s2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (c3): C3(\n",
       "    (c3): Sequential(\n",
       "      (c3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (relu3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (f4): F4(\n",
       "    (f4): Sequential(\n",
       "      (f4): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (relu4): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (f5): F5(\n",
       "    (f5): Sequential(\n",
       "      (f5): Linear(in_features=84, out_features=2, bias=True)\n",
       "      (sig5): LogSoftmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet = LeNet5()\n",
    "lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baf74168",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 1, 5, 5], expected input[16, 3, 224, 224] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2ff3aeff15ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlenet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-239bea6786ae>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc2_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-239bea6786ae>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 1, 5, 5], expected input[16, 3, 224, 224] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(lenet.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "acc_t = []\n",
    "acc_v = []\n",
    "epoch_counts = []\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_iter, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = lenet(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1250 == 1249:    # print every 1250 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in train_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = lenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_t += labels.size(0)\n",
    "            correct_t += (predicted == labels).sum().item()\n",
    "    acc_t.append(correct_t / total_t)\n",
    "            \n",
    "    correct_v = 0\n",
    "    total_v = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = lenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_v += labels.size(0)\n",
    "            correct_v += (predicted == labels).sum().item()\n",
    "    acc_v.append(correct_v / total_v)\n",
    "    \n",
    "    epoch_counts.append(epoch + 1)\n",
    "            \n",
    "    print('Epoch', epoch + 1,': Train accuracy: %.2f %%' % (100 * correct_t / total_t), ', Test accuracy: %.2f %%' % (100 * correct_v / total_v))\n",
    "    \n",
    "print('Finished Training of LeNet-5')\n",
    "\n",
    "plt.plot(epoch_counts, acc_t)\n",
    "plt.plot(epoch_counts, acc_v)\n",
    "plt.title('LeNet-5 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_iter:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = lenet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
