{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e2e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import sys\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torch.nn.init as init\n",
    "from typing import Any\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57f39d",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c455a83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(25)\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 1000),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2b84d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43693a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier[1] = nn.Linear(9216,4096)\n",
    "alexnet.classifier[4] = nn.Linear(4096,1024)\n",
    "alexnet.classifier[6] = nn.Linear(1024,2)\n",
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f25951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def getStat(train_data):\n",
    "    print('Compute mean and std for training data.')\n",
    "    print(len(train_data))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_data, batch_size=1, shuffle=False, num_workers=0,\n",
    "        pin_memory=True)\n",
    "    mean = torch.zeros(3)\n",
    "    std = torch.zeros(3)\n",
    "\n",
    "    for X, Y in train_loader:\n",
    "        for d in range(3):\n",
    "            mean[d] += X[:, d, :, :].mean()\n",
    "            std[d] += X[:, d, :, :].std()\n",
    "    mean.div_(len(train_data))\n",
    "    std.div_(len(train_data))\n",
    "    return list(mean.numpy()), list(std.numpy())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_dataset = ImageFolder(root=os.getcwd()+ \"/downloads/COVID-19-1/Train/\", transform=transforms.ToTensor())  #get_transform_for_train()\n",
    "    print(getStat(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e473a83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.3313017, 0.3313017, 0.3313017], std=[0.340617, 0.340617, 0.340617]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769cdacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os, os.path\n",
    "\n",
    "data_root = os.getcwd()\n",
    "image_path = data_root + \"/downloads/COVID-19-1/Train/\"\n",
    "train_dataset = datasets.ImageFolder(root = image_path, transform = preprocess)\n",
    "lung_list = train_dataset.class_to_idx\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "batch_size = 4\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root = data_root + \"/downloads/COVID-19-1/Test/\", transform = preprocess)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "classes = (\"Normal\", \"Abnormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bb467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(alexnet.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "acc_t = []\n",
    "acc_v = []\n",
    "epoch_counts = []\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_iter, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = alexnet(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 625 == 624:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 625))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in train_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_t += labels.size(0)\n",
    "            correct_t += (predicted == labels).sum().item()\n",
    "    acc_t.append(correct_t / total_t)\n",
    "            \n",
    "    correct_v = 0\n",
    "    total_v = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = alexnet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_v += labels.size(0)\n",
    "            correct_v += (predicted == labels).sum().item()\n",
    "    acc_v.append(correct_v / total_v)\n",
    "    \n",
    "    epoch_counts.append(epoch + 1)\n",
    "            \n",
    "    print('Epoch', epoch + 1,': Train accuracy: %.2f %%' % (100 * correct_t / total_t), ', Test accuracy: %.2f %%' % (100 * correct_v / total_v))\n",
    "    \n",
    "print('Finished Training of AlexNet')\n",
    "\n",
    "plt.plot(epoch_counts, acc_t)\n",
    "plt.plot(epoch_counts, acc_v)\n",
    "plt.title('AlexNet accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057528eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "class_FP_TP = list(0. for i in range(10))\n",
    "class_TN_FN = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_iter:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = alexnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c0 = (predicted == 0).squeeze()\n",
    "        c1 = (predicted == 1).squeeze()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_FP_TP[label] += c1[i].item()\n",
    "            class_TN_FN[label] += c0[i].item()\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "Precision0 = 100 * class_TN_FN[0] / (class_TN_FN[0] + class_TN_FN[1])\n",
    "Recall0 = 100 * class_TN_FN[0]/ (class_TN_FN[0] + class_FP_TP[0])\n",
    "F10 = 2 * (Precision0 * Recall0) / (Precision0 + Recall0)\n",
    "print('Numbers of FP for', classes[0], ':', int(class_TN_FN[1]))\n",
    "print('Numbers of FN for', classes[0], ':', int(class_FP_TP[0]))\n",
    "print('Precision of %5s : %2d %%' % (classes[0], Precision0))\n",
    "print('Recall of %5s : %2d %%' % (classes[0], Recall0))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[0], 100 * class_correct[0] / class_total[0]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[0], F10))\n",
    "print()\n",
    "\n",
    "Precision1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_FP_TP[0])\n",
    "Recall1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_TN_FN[1])\n",
    "F11 = 2 * (Precision1 * Recall1) / (Precision1 + Recall1)\n",
    "print('Numbers of FP for', classes[1], ':', int(class_FP_TP[0]))\n",
    "print('Numbers of FN for', classes[1], ':', int(class_TN_FN[1]))\n",
    "print('Precision of %5s : %2d %%' % (classes[1], Precision1))\n",
    "print('Recall of %5s : %2d %%' % (classes[1], Recall1))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[1], 100 * class_correct[1] / class_total[1]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[1], F11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ae83d",
   "metadata": {},
   "source": [
    "# SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09403cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(25)\n",
    "\n",
    "class Fire(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        squeeze_planes: int,\n",
    "        expand1x1_planes: int,\n",
    "        expand3x3_planes: int\n",
    "    ) -> None:\n",
    "        super(Fire, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
    "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
    "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
    "                                   kernel_size=1)\n",
    "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
    "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
    "                                   kernel_size=3, padding=1)\n",
    "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.squeeze_activation(self.squeeze(x))\n",
    "        return torch.cat([\n",
    "            self.expand1x1_activation(self.expand1x1(x)),\n",
    "            self.expand3x3_activation(self.expand3x3(x))\n",
    "        ], 1)\n",
    "\n",
    "class SqueezeNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        version: str = '1_0',\n",
    "        num_classes: int = 2\n",
    "    ) -> None:\n",
    "        super(SqueezeNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        if version == '1_0':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(96, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        elif version == '1_1':\n",
    "            self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(64, 16, 64, 64),\n",
    "                Fire(128, 16, 64, 64),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(128, 32, 128, 128),\n",
    "                Fire(256, 32, 128, 128),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
    "                Fire(256, 48, 192, 192),\n",
    "                Fire(384, 48, 192, 192),\n",
    "                Fire(384, 64, 256, 256),\n",
    "                Fire(512, 64, 256, 256),\n",
    "            )\n",
    "        else:\n",
    "            # FIXME: Is this needed? SqueezeNet should only be called from the\n",
    "            # FIXME: squeezenet1_x() functions\n",
    "            # FIXME: This checking is not done for the other models\n",
    "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
    "                             \"1_0 or 1_1 expected\".format(version=version))\n",
    "\n",
    "        # Final convolution is initialized differently from the rest\n",
    "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            final_conv,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                if m is final_conv:\n",
    "                    init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "                else:\n",
    "                    init.kaiming_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return torch.flatten(x, 1)\n",
    "    \n",
    "def _squeezenet(version: str, pretrained: bool, progress: bool, **kwargs: Any) -> SqueezeNet:\n",
    "    model = SqueezeNet(version, **kwargs)\n",
    "    if pretrained:\n",
    "        arch = 'squeezenet' + version\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a7d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezenet = SqueezeNet()\n",
    "squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07a62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezenet.classifier[1] = nn.Conv2d(512, 2, kernel_size=(1,1), stride=(1,1))\n",
    "squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os, os.path\n",
    "\n",
    "data_root = os.getcwd()\n",
    "image_path = data_root + \"/downloads/COVID-19-1/Train/\"\n",
    "train_dataset = datasets.ImageFolder(root = image_path, transform = preprocess)\n",
    "lung_list = train_dataset.class_to_idx\n",
    "\n",
    "train_num = len(train_dataset)\n",
    "batch_size = 16\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(root = data_root + \"/downloads/COVID-19-1/Test/\", transform = preprocess)\n",
    "val_iter = torch.utils.data.DataLoader(val_dataset, batch_size = batch_size, shuffle = True, num_workers = 2, drop_last = True)\n",
    "\n",
    "classes = (\"Normal\", \"Abnormal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df74a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(squeezenet.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "acc_t = []\n",
    "acc_v = []\n",
    "epoch_counts = []\n",
    "\n",
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    for i, data in enumerate(train_iter, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = squeezenet(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #Time\n",
    "        end_time = time.time()\n",
    "        time_taken = end_time - start_time\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 5000))\n",
    "            print('Time:',time_taken)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Testing Accuracy\n",
    "    correct_t = 0\n",
    "    total_t = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in train_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = squeezenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_t += labels.size(0)\n",
    "            correct_t += (predicted == labels).sum().item()\n",
    "    acc_t.append(correct_t / total_t)\n",
    "            \n",
    "    correct_v = 0\n",
    "    total_v = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_iter:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = squeezenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_v += labels.size(0)\n",
    "            correct_v += (predicted == labels).sum().item()\n",
    "    acc_v.append(correct_v / total_v)\n",
    "    \n",
    "    epoch_counts.append(epoch + 1)\n",
    "            \n",
    "    print('Epoch', epoch + 1,': Train accuracy: %.2f %%' % (100 * correct_t / total_t), ', Test accuracy: %.2f %%' % (100 * correct_v / total_v))\n",
    "    \n",
    "print('Finished Training of SqueezeNet')\n",
    "\n",
    "plt.plot(epoch_counts, acc_t)\n",
    "plt.plot(epoch_counts, acc_v)\n",
    "plt.title('SqueezeNet accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd89a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "class_FP_TP = list(0. for i in range(10))\n",
    "class_TN_FN = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in val_iter:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = squeezenet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c0 = (predicted == 0).squeeze()\n",
    "        c1 = (predicted == 1).squeeze()\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_FP_TP[label] += c1[i].item()\n",
    "            class_TN_FN[label] += c0[i].item()\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "Precision0 = 100 * class_TN_FN[0] / (class_TN_FN[0] + class_TN_FN[1])\n",
    "Recall0 = 100 * class_TN_FN[0]/ (class_TN_FN[0] + class_FP_TP[0])\n",
    "F10 = 2 * (Precision0 * Recall0) / (Precision0 + Recall0)\n",
    "print('Numbers of FP for', classes[0], ':', int(class_TN_FN[1]))\n",
    "print('Numbers of FN for', classes[0], ':', int(class_FP_TP[0]))\n",
    "print('Precision of %5s : %2d %%' % (classes[0], Precision0))\n",
    "print('Recall of %5s : %2d %%' % (classes[0], Recall0))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[0], 100 * class_correct[0] / class_total[0]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[0], F10))\n",
    "print()\n",
    "\n",
    "Precision1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_FP_TP[0])\n",
    "Recall1 = 100 * class_FP_TP[1] / (class_FP_TP[1] + class_TN_FN[1])\n",
    "F11 = 2 * (Precision1 * Recall1) / (Precision1 + Recall1)\n",
    "print('Numbers of FP for', classes[1], ':', int(class_FP_TP[0]))\n",
    "print('Numbers of FN for', classes[1], ':', int(class_TN_FN[1]))\n",
    "print('Precision of %5s : %2d %%' % (classes[1], Precision1))\n",
    "print('Recall of %5s : %2d %%' % (classes[1], Recall1))\n",
    "print('Accuracy of %5s : %2d %%' % (classes[1], 100 * class_correct[1] / class_total[1]))\n",
    "print('F1-score of %5s : %2d %%' % (classes[1], F11))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
